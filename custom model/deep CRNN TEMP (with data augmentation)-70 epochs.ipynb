{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75247114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4276, Val: 535, Test: 535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set up the data directory\n",
    "data_dir = 'Register Numbers/'\n",
    "\n",
    "# Load image paths and labels\n",
    "image_pairs = [\n",
    "    (os.path.join(data_dir, f), f.split('.')[0]) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.endswith('.png')\n",
    "]\n",
    "\n",
    "# Validate labels\n",
    "def validate_label(label):\n",
    "    if len(label) != 12 or not label.isdigit():\n",
    "        raise ValueError(f\"Invalid register number: {label}\")\n",
    "    return label\n",
    "\n",
    "cleaned_pairs = [(path, validate_label(label[:12])) for path, label in image_pairs]\n",
    "\n",
    "# Split the data\n",
    "random.shuffle(cleaned_pairs)\n",
    "total = len(cleaned_pairs)\n",
    "train = cleaned_pairs[:int(0.8 * total)]\n",
    "val = cleaned_pairs[int(0.8 * total):int(0.9 * total)]\n",
    "test = cleaned_pairs[int(0.9 * total):]\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ef5caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegisterNumberDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_seq = [int(digit) + 1 for digit in label]  # 0->1, 1->2, ..., 9->10\n",
    "        return image, torch.tensor(label_seq, dtype=torch.long)\n",
    "\n",
    "# Custom transform for random brightness\n",
    "class RandomBrightness(object):\n",
    "    def __init__(self, delta=0.3):\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, img):\n",
    "        brightness = random.uniform(-self.delta, self.delta)\n",
    "        img = torch.tensor(np.array(img)).float() / 255.0  # Convert to tensor [0,1]\n",
    "        img = img + brightness\n",
    "        img = torch.clamp(img, 0, 1)  # Keep values between 0 and 1\n",
    "        return Image.fromarray((img.numpy() * 255).astype(np.uint8))\n",
    "\n",
    "# Training transform with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),  # Rotate between -15 and 15 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),  # Shift and scale\n",
    "    RandomBrightness(0.3),  # Random brightness adjustment\n",
    "    transforms.GaussianBlur(kernel_size=3),  # Slight blur\n",
    "    transforms.Resize((32, 256)),  # Ensure consistent size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x)),  # Add noise\n",
    "    transforms.Lambda(lambda x: torch.clamp(x, -1, 1)),  # Clamp after noise\n",
    "])\n",
    "\n",
    "# Validation/test transform (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = RegisterNumberDataset([p for p, _ in train], [l for _, l in train], transform=train_transform)\n",
    "val_dataset = RegisterNumberDataset([p for p, _ in val], [l for _, l in val], transform=val_test_transform)\n",
    "test_dataset = RegisterNumberDataset([p for p, _ in test], [l for _, l in test], transform=val_test_transform)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8629e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Dropout2d(p=0.3, inplace=False)\n",
       "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): ReLU()\n",
       "    (22): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (23): Dropout2d(p=0.3, inplace=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(2, 1), stride=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "  )\n",
       "  (rnn): LSTM(512, 256, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        # CNN component with dropout\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 64, 16, W/2)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 128, 8, W/4)\n",
    "            nn.Dropout2d(0.3),  # Dropout after second maxpool\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 256, 4, W/4)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 512, 2, W/4)\n",
    "            nn.Dropout2d(0.3),  # Dropout after fourth maxpool\n",
    "            nn.Conv2d(512, 512, kernel_size=(2,1)),  # (N, 512, 1, W/4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # LSTM with dropout between layers\n",
    "        self.rnn = nn.LSTM(512, 256, num_layers=2, bidirectional=True, dropout=0.3)\n",
    "        # Dropout before the fully connected layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes)  # 512 because bidirectional (256 * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through CNN\n",
    "        x = self.cnn(x)  # (N, 512, 1, W/4)\n",
    "        x = x.squeeze(2)  # (N, 512, W/4)\n",
    "        x = x.permute(2, 0, 1)  # (W/4, N, 512) for LSTM\n",
    "        # Pass through LSTM\n",
    "        x, _ = self.rnn(x)  # (W/4, N, 512)\n",
    "        # Apply dropout before FC\n",
    "        x = self.dropout(x)\n",
    "        # Fully connected layer for classification\n",
    "        x = self.fc(x)  # (W/4, N, num_classes)\n",
    "        return x\n",
    "\n",
    "# Initialize the model (assuming 11 classes: blank + digits 0-9)\n",
    "model = CRNN(num_classes=11)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "003b9ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Train Loss: 1.5511, Val Loss: 1.2096, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 2/120, Train Loss: 1.0808, Val Loss: 1.0542, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 3/120, Train Loss: 1.0141, Val Loss: 1.0166, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 4/120, Train Loss: 1.0013, Val Loss: 1.0188, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 5/120, Train Loss: 0.9872, Val Loss: 0.9689, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 6/120, Train Loss: 0.9493, Val Loss: 0.9418, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 7/120, Train Loss: 0.9322, Val Loss: 0.9417, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 8/120, Train Loss: 0.9240, Val Loss: 0.9376, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 9/120, Train Loss: 0.9235, Val Loss: 0.9365, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 10/120, Train Loss: 0.9154, Val Loss: 0.9248, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 11/120, Train Loss: 0.9238, Val Loss: 0.9363, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 12/120, Train Loss: 0.9142, Val Loss: 0.9150, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 13/120, Train Loss: 0.9103, Val Loss: 0.9166, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 14/120, Train Loss: 0.9091, Val Loss: 0.9138, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 15/120, Train Loss: 0.9072, Val Loss: 0.9123, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 16/120, Train Loss: 0.9066, Val Loss: 0.9094, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 17/120, Train Loss: 0.9041, Val Loss: 0.9081, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 18/120, Train Loss: 0.9024, Val Loss: 0.9028, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 19/120, Train Loss: 0.8986, Val Loss: 0.8840, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 20/120, Train Loss: 0.8976, Val Loss: 0.8972, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 21/120, Train Loss: 0.8602, Val Loss: 0.7981, Train Acc: 0.02%, Val Acc: 0.19%\n",
      "Epoch 22/120, Train Loss: 0.8104, Val Loss: 0.7529, Train Acc: 0.12%, Val Acc: 0.00%\n",
      "Epoch 23/120, Train Loss: 0.7687, Val Loss: 0.7456, Train Acc: 0.12%, Val Acc: 0.37%\n",
      "Epoch 24/120, Train Loss: 0.7273, Val Loss: 0.6693, Train Acc: 0.33%, Val Acc: 0.00%\n",
      "Epoch 25/120, Train Loss: 0.6845, Val Loss: 0.6124, Train Acc: 0.54%, Val Acc: 0.93%\n",
      "Epoch 26/120, Train Loss: 0.6718, Val Loss: 0.6108, Train Acc: 0.80%, Val Acc: 0.93%\n",
      "Epoch 27/120, Train Loss: 0.7705, Val Loss: 0.7308, Train Acc: 0.49%, Val Acc: 0.19%\n",
      "Epoch 28/120, Train Loss: 0.9043, Val Loss: 0.8038, Train Acc: 0.07%, Val Acc: 0.00%\n",
      "Epoch 29/120, Train Loss: 0.8028, Val Loss: 0.6559, Train Acc: 0.21%, Val Acc: 0.93%\n",
      "Epoch 30/120, Train Loss: 0.7009, Val Loss: 0.6104, Train Acc: 0.58%, Val Acc: 1.50%\n",
      "Epoch 31/120, Train Loss: 0.6609, Val Loss: 0.5762, Train Acc: 0.91%, Val Acc: 1.31%\n",
      "Epoch 32/120, Train Loss: 0.6168, Val Loss: 0.5572, Train Acc: 1.31%, Val Acc: 2.62%\n",
      "Epoch 33/120, Train Loss: 0.5819, Val Loss: 0.4978, Train Acc: 2.32%, Val Acc: 4.11%\n",
      "Epoch 34/120, Train Loss: 0.5640, Val Loss: 0.4824, Train Acc: 2.71%, Val Acc: 4.67%\n",
      "Epoch 35/120, Train Loss: 0.5345, Val Loss: 0.4510, Train Acc: 3.30%, Val Acc: 6.17%\n",
      "Epoch 36/120, Train Loss: 0.5119, Val Loss: 0.4282, Train Acc: 4.14%, Val Acc: 8.04%\n",
      "Epoch 37/120, Train Loss: 0.4865, Val Loss: 0.4140, Train Acc: 4.86%, Val Acc: 9.35%\n",
      "Epoch 38/120, Train Loss: 0.4778, Val Loss: 0.3978, Train Acc: 5.68%, Val Acc: 9.35%\n",
      "Epoch 39/120, Train Loss: 0.4651, Val Loss: 0.3944, Train Acc: 5.45%, Val Acc: 10.28%\n",
      "Epoch 40/120, Train Loss: 0.4625, Val Loss: 0.3849, Train Acc: 5.94%, Val Acc: 10.28%\n",
      "Epoch 41/120, Train Loss: 0.4816, Val Loss: 0.3841, Train Acc: 5.40%, Val Acc: 12.52%\n",
      "Epoch 42/120, Train Loss: 0.4417, Val Loss: 0.3495, Train Acc: 6.88%, Val Acc: 13.64%\n",
      "Epoch 43/120, Train Loss: 0.4305, Val Loss: 0.3317, Train Acc: 7.81%, Val Acc: 14.77%\n",
      "Epoch 44/120, Train Loss: 0.4206, Val Loss: 0.3186, Train Acc: 9.31%, Val Acc: 15.70%\n",
      "Epoch 45/120, Train Loss: 0.3991, Val Loss: 0.3247, Train Acc: 8.93%, Val Acc: 16.26%\n",
      "Epoch 46/120, Train Loss: 0.3947, Val Loss: 0.3325, Train Acc: 10.08%, Val Acc: 14.21%\n",
      "Epoch 47/120, Train Loss: 0.3993, Val Loss: 0.2972, Train Acc: 9.52%, Val Acc: 19.25%\n",
      "Epoch 48/120, Train Loss: 0.3890, Val Loss: 0.2946, Train Acc: 10.64%, Val Acc: 18.50%\n",
      "Epoch 49/120, Train Loss: 0.3740, Val Loss: 0.2887, Train Acc: 11.11%, Val Acc: 19.25%\n",
      "Epoch 50/120, Train Loss: 0.3587, Val Loss: 0.2562, Train Acc: 12.79%, Val Acc: 24.30%\n",
      "Epoch 51/120, Train Loss: 0.3771, Val Loss: 0.2634, Train Acc: 12.02%, Val Acc: 24.86%\n",
      "Epoch 52/120, Train Loss: 0.3633, Val Loss: 0.2901, Train Acc: 12.30%, Val Acc: 24.11%\n",
      "Epoch 53/120, Train Loss: 0.3463, Val Loss: 0.2623, Train Acc: 14.36%, Val Acc: 28.04%\n",
      "Epoch 54/120, Train Loss: 0.3389, Val Loss: 0.2500, Train Acc: 14.97%, Val Acc: 28.97%\n",
      "Epoch 55/120, Train Loss: 0.3294, Val Loss: 0.2272, Train Acc: 15.95%, Val Acc: 33.64%\n",
      "Epoch 56/120, Train Loss: 0.3221, Val Loss: 0.2256, Train Acc: 17.14%, Val Acc: 30.84%\n",
      "Epoch 57/120, Train Loss: 0.3305, Val Loss: 0.2150, Train Acc: 16.88%, Val Acc: 34.95%\n",
      "Epoch 58/120, Train Loss: 0.3138, Val Loss: 0.2101, Train Acc: 19.01%, Val Acc: 35.51%\n",
      "Epoch 59/120, Train Loss: 0.3562, Val Loss: 0.3536, Train Acc: 16.56%, Val Acc: 19.25%\n",
      "Epoch 60/120, Train Loss: 0.3535, Val Loss: 0.2033, Train Acc: 15.08%, Val Acc: 37.38%\n",
      "Epoch 61/120, Train Loss: 0.3224, Val Loss: 0.2141, Train Acc: 17.84%, Val Acc: 33.64%\n",
      "Epoch 62/120, Train Loss: 0.3306, Val Loss: 0.2265, Train Acc: 19.06%, Val Acc: 32.90%\n",
      "Epoch 63/120, Train Loss: 0.3243, Val Loss: 0.1982, Train Acc: 18.97%, Val Acc: 38.13%\n",
      "Epoch 64/120, Train Loss: 0.3061, Val Loss: 0.1952, Train Acc: 20.04%, Val Acc: 37.38%\n",
      "Epoch 65/120, Train Loss: 0.3124, Val Loss: 0.1949, Train Acc: 20.16%, Val Acc: 42.24%\n",
      "Epoch 66/120, Train Loss: 0.3362, Val Loss: 0.1872, Train Acc: 19.67%, Val Acc: 40.93%\n",
      "Epoch 67/120, Train Loss: 0.3142, Val Loss: 0.1833, Train Acc: 19.71%, Val Acc: 42.24%\n",
      "Epoch 68/120, Train Loss: 0.3175, Val Loss: 0.2151, Train Acc: 20.53%, Val Acc: 40.19%\n",
      "Epoch 69/120, Train Loss: 0.3420, Val Loss: 0.1867, Train Acc: 17.33%, Val Acc: 40.00%\n",
      "Epoch 70/120, Train Loss: 0.2995, Val Loss: 0.1775, Train Acc: 21.47%, Val Acc: 41.87%\n",
      "Epoch 71/120, Train Loss: 0.2853, Val Loss: 0.1694, Train Acc: 23.22%, Val Acc: 45.79%\n",
      "Epoch 72/120, Train Loss: 0.2869, Val Loss: 0.1706, Train Acc: 23.22%, Val Acc: 47.48%\n",
      "Epoch 73/120, Train Loss: 0.2751, Val Loss: 0.1493, Train Acc: 24.02%, Val Acc: 51.21%\n",
      "Epoch 74/120, Train Loss: 0.2548, Val Loss: 0.1435, Train Acc: 28.44%, Val Acc: 59.07%\n",
      "Epoch 75/120, Train Loss: 0.2408, Val Loss: 0.1345, Train Acc: 31.48%, Val Acc: 59.25%\n",
      "Epoch 76/120, Train Loss: 0.2481, Val Loss: 0.1400, Train Acc: 31.48%, Val Acc: 61.31%\n",
      "Epoch 77/120, Train Loss: 0.2437, Val Loss: 0.1337, Train Acc: 33.21%, Val Acc: 62.80%\n",
      "Epoch 78/120, Train Loss: 0.2368, Val Loss: 0.1256, Train Acc: 33.93%, Val Acc: 65.79%\n",
      "Epoch 79/120, Train Loss: 0.2204, Val Loss: 0.1119, Train Acc: 36.44%, Val Acc: 69.72%\n",
      "Epoch 80/120, Train Loss: 0.2165, Val Loss: 0.1223, Train Acc: 37.37%, Val Acc: 67.85%\n",
      "Epoch 81/120, Train Loss: 0.2249, Val Loss: 0.1069, Train Acc: 37.07%, Val Acc: 73.64%\n",
      "Epoch 82/120, Train Loss: 0.2116, Val Loss: 0.0974, Train Acc: 39.48%, Val Acc: 74.39%\n",
      "Epoch 83/120, Train Loss: 0.2154, Val Loss: 0.0998, Train Acc: 38.89%, Val Acc: 75.33%\n",
      "Epoch 84/120, Train Loss: 0.2034, Val Loss: 0.0993, Train Acc: 41.56%, Val Acc: 76.26%\n",
      "Epoch 85/120, Train Loss: 0.2250, Val Loss: 0.0955, Train Acc: 40.13%, Val Acc: 76.64%\n",
      "Epoch 86/120, Train Loss: 0.1981, Val Loss: 0.0831, Train Acc: 43.85%, Val Acc: 79.25%\n",
      "Epoch 87/120, Train Loss: 0.1919, Val Loss: 0.0832, Train Acc: 44.18%, Val Acc: 79.63%\n",
      "Epoch 88/120, Train Loss: 0.1953, Val Loss: 0.0816, Train Acc: 44.11%, Val Acc: 78.88%\n",
      "Epoch 89/120, Train Loss: 0.1783, Val Loss: 0.0791, Train Acc: 47.05%, Val Acc: 82.06%\n",
      "Epoch 90/120, Train Loss: 0.1788, Val Loss: 0.0837, Train Acc: 46.54%, Val Acc: 81.68%\n",
      "Epoch 91/120, Train Loss: 0.1812, Val Loss: 0.0948, Train Acc: 46.30%, Val Acc: 77.01%\n",
      "Epoch 92/120, Train Loss: 0.1816, Val Loss: 0.0762, Train Acc: 46.49%, Val Acc: 84.30%\n",
      "Epoch 93/120, Train Loss: 0.1775, Val Loss: 0.0768, Train Acc: 47.94%, Val Acc: 81.50%\n",
      "Epoch 94/120, Train Loss: 0.1695, Val Loss: 0.0741, Train Acc: 49.95%, Val Acc: 83.93%\n",
      "Epoch 95/120, Train Loss: 0.1743, Val Loss: 0.0783, Train Acc: 50.42%, Val Acc: 82.62%\n",
      "Epoch 96/120, Train Loss: 0.1705, Val Loss: 0.0775, Train Acc: 49.37%, Val Acc: 85.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/120, Train Loss: 0.1671, Val Loss: 0.0815, Train Acc: 50.80%, Val Acc: 83.93%\n",
      "Epoch 98/120, Train Loss: 0.1655, Val Loss: 0.0645, Train Acc: 51.08%, Val Acc: 87.10%\n",
      "Epoch 99/120, Train Loss: 0.1783, Val Loss: 0.0757, Train Acc: 50.14%, Val Acc: 84.67%\n",
      "Epoch 100/120, Train Loss: 0.1691, Val Loss: 0.0582, Train Acc: 51.40%, Val Acc: 87.10%\n",
      "Epoch 101/120, Train Loss: 0.1578, Val Loss: 0.0581, Train Acc: 53.93%, Val Acc: 88.97%\n",
      "Epoch 102/120, Train Loss: 0.1557, Val Loss: 0.0540, Train Acc: 54.30%, Val Acc: 89.53%\n",
      "Epoch 103/120, Train Loss: 0.1484, Val Loss: 0.0561, Train Acc: 56.15%, Val Acc: 88.04%\n",
      "Epoch 104/120, Train Loss: 0.1554, Val Loss: 0.0581, Train Acc: 53.79%, Val Acc: 89.16%\n",
      "Epoch 105/120, Train Loss: 0.1498, Val Loss: 0.0584, Train Acc: 55.26%, Val Acc: 90.84%\n",
      "Epoch 106/120, Train Loss: 0.1481, Val Loss: 0.0616, Train Acc: 57.20%, Val Acc: 88.04%\n",
      "Epoch 107/120, Train Loss: 0.1517, Val Loss: 0.0588, Train Acc: 56.17%, Val Acc: 90.09%\n",
      "Epoch 108/120, Train Loss: 0.1533, Val Loss: 0.0528, Train Acc: 55.40%, Val Acc: 91.40%\n",
      "Epoch 109/120, Train Loss: 0.1495, Val Loss: 0.0499, Train Acc: 56.29%, Val Acc: 91.21%\n",
      "Epoch 110/120, Train Loss: 0.1433, Val Loss: 0.0523, Train Acc: 58.37%, Val Acc: 91.21%\n",
      "Epoch 111/120, Train Loss: 0.1436, Val Loss: 0.0528, Train Acc: 57.32%, Val Acc: 91.78%\n",
      "Epoch 112/120, Train Loss: 0.1460, Val Loss: 0.0496, Train Acc: 56.52%, Val Acc: 92.90%\n",
      "Epoch 113/120, Train Loss: 0.1337, Val Loss: 0.0501, Train Acc: 60.73%, Val Acc: 92.34%\n",
      "Epoch 114/120, Train Loss: 0.1385, Val Loss: 0.0506, Train Acc: 59.35%, Val Acc: 91.96%\n",
      "Epoch 115/120, Train Loss: 0.1371, Val Loss: 0.0476, Train Acc: 58.37%, Val Acc: 92.90%\n",
      "Epoch 116/120, Train Loss: 0.1364, Val Loss: 0.0487, Train Acc: 59.75%, Val Acc: 92.34%\n",
      "Epoch 117/120, Train Loss: 0.1494, Val Loss: 0.0674, Train Acc: 56.20%, Val Acc: 90.09%\n",
      "Epoch 118/120, Train Loss: 0.1433, Val Loss: 0.0653, Train Acc: 58.98%, Val Acc: 88.41%\n",
      "Epoch 119/120, Train Loss: 0.1752, Val Loss: 0.0609, Train Acc: 53.16%, Val Acc: 88.79%\n",
      "Epoch 120/120, Train Loss: 0.1452, Val Loss: 0.0513, Train Acc: 57.65%, Val Acc: 92.15%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CTCLoss(blank=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Decoding function (used in both training and evaluation)\n",
    "def decode_predictions(outputs):\n",
    "    outputs = outputs.softmax(2).argmax(2)  # (T, N)\n",
    "    batch_size = outputs.size(1)\n",
    "    decoded = []\n",
    "    for b in range(batch_size):\n",
    "        seq = outputs[:, b].cpu().numpy()\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "        decoded.append(''.join(map(str, result)))\n",
    "    return decoded\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 120\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # (W/4, N, num_classes)\n",
    "        outputs_log = outputs.log_softmax(2)\n",
    "        batch_size = images.size(0)\n",
    "        input_lengths = torch.full((batch_size,), outputs.size(0), dtype=torch.long, device=device)\n",
    "        target_lengths = torch.full((batch_size,), 12, dtype=torch.long, device=device)\n",
    "        targets_flat = targets.view(-1)\n",
    "        loss = criterion(outputs_log, targets_flat, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        predictions = decode_predictions(outputs)\n",
    "        target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "        for pred, target in zip(predictions, target_labels):\n",
    "            if pred == target:\n",
    "                train_correct += 1\n",
    "            train_total += 1\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs_log = outputs.log_softmax(2)\n",
    "            batch_size = images.size(0)\n",
    "            input_lengths = torch.full((batch_size,), outputs.size(0), dtype=torch.long, device=device)\n",
    "            target_lengths = torch.full((batch_size,), 12, dtype=torch.long, device=device)\n",
    "            targets_flat = targets.view(-1)\n",
    "            loss = criterion(outputs_log, targets_flat, input_lengths, target_lengths)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            predictions = decode_predictions(outputs)\n",
    "            target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "            for pred, target in zip(predictions, target_labels):\n",
    "                if pred == target:\n",
    "                    val_correct += 1\n",
    "                val_total += 1\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total * 100\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58268529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.41%\n"
     ]
    }
   ],
   "source": [
    "def decode_predictions(outputs):\n",
    "    outputs = outputs.softmax(2).argmax(2)  # (T, N) -> e.g., (64, N)\n",
    "    batch_size = outputs.size(1)\n",
    "    decoded = []\n",
    "    for b in range(batch_size):\n",
    "        seq = outputs[:, b].cpu().numpy()  # (T,)\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "        decoded.append(''.join(map(str, result)))\n",
    "    return decoded\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)  # (T, N, num_classes)\n",
    "        predictions = decode_predictions(outputs)\n",
    "        target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "        for pred, target in zip(predictions, target_labels):\n",
    "            if pred == target:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(f\"Test Accuracy: {correct/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Accuracy: 92.15% for 70 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4da4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Register Number: 212223240005\n"
     ]
    }
   ],
   "source": [
    "def predict_register_number(model, image_path, device, transform):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # (1, 1, 32, 256)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image)  # (T, 1, num_classes), e.g., (64, 1, 11)\n",
    "        output = output.squeeze(1)  # (T, num_classes)\n",
    "        output = output.softmax(1).argmax(1)  # (T,)\n",
    "        seq = output.cpu().numpy()\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "    return ''.join(map(str, result))\n",
    "\n",
    "# Test with your image\n",
    "image_path = 'my_reg.png'  # Replace with your image path\n",
    "predicted_number = predict_register_number(model, image_path, device, val_test_transform)\n",
    "print(f\"Predicted Register Number: {predicted_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87573f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Register Number: 212223240068 for 92.15% accurate model\n",
    "# for my_reg.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d68138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
