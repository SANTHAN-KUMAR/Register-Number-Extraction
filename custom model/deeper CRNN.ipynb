{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20741a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4276, Val: 535, Test: 535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set up the data directory\n",
    "data_dir = 'Register Numbers/'\n",
    "\n",
    "# Load image paths and labels\n",
    "image_pairs = [\n",
    "    (os.path.join(data_dir, f), f.split('.')[0]) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.endswith('.png')\n",
    "]\n",
    "\n",
    "# Validate labels\n",
    "def validate_label(label):\n",
    "    if len(label) != 12 or not label.isdigit():\n",
    "        raise ValueError(f\"Invalid register number: {label}\")\n",
    "    return label\n",
    "\n",
    "cleaned_pairs = [(path, validate_label(label[:12])) for path, label in image_pairs]\n",
    "\n",
    "# Split the data\n",
    "random.shuffle(cleaned_pairs)\n",
    "total = len(cleaned_pairs)\n",
    "train = cleaned_pairs[:int(0.8 * total)]\n",
    "val = cleaned_pairs[int(0.8 * total):int(0.9 * total)]\n",
    "test = cleaned_pairs[int(0.9 * total):]\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acb8025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegisterNumberDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_seq = [int(digit) + 1 for digit in label]  # 0->1, 1->2, ..., 9->10\n",
    "        return image, torch.tensor(label_seq, dtype=torch.long)\n",
    "\n",
    "# Custom transform for random brightness\n",
    "class RandomBrightness(object):\n",
    "    def __init__(self, delta=0.3):\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, img):\n",
    "        brightness = random.uniform(-self.delta, self.delta)\n",
    "        img = torch.tensor(np.array(img)).float() / 255.0  # Convert to tensor [0,1]\n",
    "        img = img + brightness\n",
    "        img = torch.clamp(img, 0, 1)  # Keep values between 0 and 1\n",
    "        return Image.fromarray((img.numpy() * 255).astype(np.uint8))\n",
    "\n",
    "# Training transform with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),  # Rotate between -15 and 15 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),  # Shift and scale\n",
    "    RandomBrightness(0.3),  # Random brightness adjustment\n",
    "    transforms.GaussianBlur(kernel_size=3),  # Slight blur\n",
    "    transforms.Resize((32, 256)),  # Ensure consistent size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x)),  # Add noise\n",
    "    transforms.Lambda(lambda x: torch.clamp(x, -1, 1)),  # Clamp after noise\n",
    "])\n",
    "\n",
    "# Validation/test transform (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = RegisterNumberDataset([p for p, _ in train], [l for _, l in train], transform=train_transform)\n",
    "val_dataset = RegisterNumberDataset([p for p, _ in val], [l for _, l in val], transform=val_test_transform)\n",
    "test_dataset = RegisterNumberDataset([p for p, _ in test], [l for _, l in test], transform=val_test_transform)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93932269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(2, 1), stride=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU()\n",
       "  )\n",
       "  (rnn): LSTM(512, 256, num_layers=2, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 64, 16, W/2)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 128, 8, W/4)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 256, 4, W/4)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 512, 2, W/4)\n",
    "            nn.Conv2d(512, 512, kernel_size=(2,1)),  # (N, 512, 1, W/4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rnn = nn.LSTM(512, 256, num_layers=2, bidirectional=True)\n",
    "        self.fc = nn.Linear(512, num_classes)  # 512 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)  # (N, 512, 1, W/4)\n",
    "        x = x.squeeze(2)  # (N, 512, W/4)\n",
    "        x = x.permute(2, 0, 1)  # (W/4, N, 512)\n",
    "        x, _ = self.rnn(x)  # (W/4, N, 512)\n",
    "        x = self.fc(x)  # (W/4, N, num_classes)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = CRNN(num_classes=11)  # 11 classes: blank + 0-9\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b44281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70, Train Loss: 1.5131, Val Loss: 1.1649, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 2/70, Train Loss: 0.9897, Val Loss: 0.9598, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 3/70, Train Loss: 0.8565, Val Loss: 0.8625, Train Acc: 0.00%, Val Acc: 0.00%\n",
      "Epoch 4/70, Train Loss: 0.7350, Val Loss: 0.6632, Train Acc: 0.02%, Val Acc: 0.19%\n",
      "Epoch 5/70, Train Loss: 0.6321, Val Loss: 0.6265, Train Acc: 0.40%, Val Acc: 0.56%\n",
      "Epoch 6/70, Train Loss: 0.5456, Val Loss: 0.4566, Train Acc: 1.87%, Val Acc: 5.98%\n",
      "Epoch 7/70, Train Loss: 0.4436, Val Loss: 0.3915, Train Acc: 6.45%, Val Acc: 14.77%\n",
      "Epoch 8/70, Train Loss: 0.3811, Val Loss: 0.3228, Train Acc: 12.98%, Val Acc: 19.44%\n",
      "Epoch 9/70, Train Loss: 0.3362, Val Loss: 0.3130, Train Acc: 17.63%, Val Acc: 19.81%\n",
      "Epoch 10/70, Train Loss: 0.3085, Val Loss: 0.2705, Train Acc: 22.85%, Val Acc: 31.59%\n",
      "Epoch 11/70, Train Loss: 0.2705, Val Loss: 0.1956, Train Acc: 30.87%, Val Acc: 45.79%\n",
      "Epoch 12/70, Train Loss: 0.2483, Val Loss: 0.2087, Train Acc: 34.82%, Val Acc: 45.42%\n",
      "Epoch 13/70, Train Loss: 0.2310, Val Loss: 0.1228, Train Acc: 38.91%, Val Acc: 66.36%\n",
      "Epoch 14/70, Train Loss: 0.2075, Val Loss: 0.1461, Train Acc: 43.36%, Val Acc: 60.75%\n",
      "Epoch 15/70, Train Loss: 0.2014, Val Loss: 0.1299, Train Acc: 45.11%, Val Acc: 64.49%\n",
      "Epoch 16/70, Train Loss: 0.1962, Val Loss: 0.1070, Train Acc: 46.28%, Val Acc: 74.02%\n",
      "Epoch 17/70, Train Loss: 0.1828, Val Loss: 0.1141, Train Acc: 47.05%, Val Acc: 75.14%\n",
      "Epoch 18/70, Train Loss: 0.1686, Val Loss: 0.0921, Train Acc: 51.15%, Val Acc: 80.93%\n",
      "Epoch 19/70, Train Loss: 0.1654, Val Loss: 0.0929, Train Acc: 53.74%, Val Acc: 79.44%\n",
      "Epoch 20/70, Train Loss: 0.1560, Val Loss: 0.0849, Train Acc: 55.82%, Val Acc: 83.36%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CTCLoss(blank=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Decoding function (used in both training and evaluation)\n",
    "def decode_predictions(outputs):\n",
    "    outputs = outputs.softmax(2).argmax(2)  # (T, N)\n",
    "    batch_size = outputs.size(1)\n",
    "    decoded = []\n",
    "    for b in range(batch_size):\n",
    "        seq = outputs[:, b].cpu().numpy()\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "        decoded.append(''.join(map(str, result)))\n",
    "    return decoded\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 70\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # (W/4, N, num_classes)\n",
    "        outputs_log = outputs.log_softmax(2)\n",
    "        batch_size = images.size(0)\n",
    "        input_lengths = torch.full((batch_size,), outputs.size(0), dtype=torch.long, device=device)\n",
    "        target_lengths = torch.full((batch_size,), 12, dtype=torch.long, device=device)\n",
    "        targets_flat = targets.view(-1)\n",
    "        loss = criterion(outputs_log, targets_flat, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        predictions = decode_predictions(outputs)\n",
    "        target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "        for pred, target in zip(predictions, target_labels):\n",
    "            if pred == target:\n",
    "                train_correct += 1\n",
    "            train_total += 1\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs_log = outputs.log_softmax(2)\n",
    "            batch_size = images.size(0)\n",
    "            input_lengths = torch.full((batch_size,), outputs.size(0), dtype=torch.long, device=device)\n",
    "            target_lengths = torch.full((batch_size,), 12, dtype=torch.long, device=device)\n",
    "            targets_flat = targets.view(-1)\n",
    "            loss = criterion(outputs_log, targets_flat, input_lengths, target_lengths)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            predictions = decode_predictions(outputs)\n",
    "            target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "            for pred, target in zip(predictions, target_labels):\n",
    "                if pred == target:\n",
    "                    val_correct += 1\n",
    "                val_total += 1\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total * 100\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58533f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.59%\n"
     ]
    }
   ],
   "source": [
    "def decode_predictions(outputs):\n",
    "    outputs = outputs.softmax(2).argmax(2)  # (T, N) -> e.g., (64, N)\n",
    "    batch_size = outputs.size(1)\n",
    "    decoded = []\n",
    "    for b in range(batch_size):\n",
    "        seq = outputs[:, b].cpu().numpy()  # (T,)\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "        decoded.append(''.join(map(str, result)))\n",
    "    return decoded\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)  # (T, N, num_classes)\n",
    "        predictions = decode_predictions(outputs)\n",
    "        target_labels = [''.join(str(d - 1) for d in t.tolist()) for t in targets]\n",
    "        for pred, target in zip(predictions, target_labels):\n",
    "            if pred == target:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(f\"Test Accuracy: {correct/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ce1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Register Number: 212223240046\n"
     ]
    }
   ],
   "source": [
    "def predict_register_number(model, image_path, device, transform):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # (1, 1, 32, 256)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image)  # (T, 1, num_classes), e.g., (64, 1, 11)\n",
    "        output = output.squeeze(1)  # (T, num_classes)\n",
    "        output = output.softmax(1).argmax(1)  # (T,)\n",
    "        seq = output.cpu().numpy()\n",
    "        prev = -1\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:\n",
    "                result.append(s - 1)\n",
    "            prev = s\n",
    "    return ''.join(map(str, result))\n",
    "\n",
    "# Test with your image\n",
    "image_path = 'Register Numbers/212223240046.png'  # Replace with your image path\n",
    "predicted_number = predict_register_number(model, image_path, device, transform)\n",
    "print(f\"Predicted Register Number: {predicted_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b70bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(image_path).convert('L')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Predicted Register Number: {predicted_number}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Register Number: 21222232212 for my reg no\n",
    "    \n",
    "    Epoch 16/20, Loss: 0.0241\n",
    "Epoch 17/20, Loss: 0.0203\n",
    "Epoch 18/20, Loss: 0.0254\n",
    "Epoch 19/20, Loss: 0.0226\n",
    "Epoch 20/20, Loss: 0.0247\n",
    "# Test Accuracy: 89.35%\n",
    "# for 20 epochssssss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
