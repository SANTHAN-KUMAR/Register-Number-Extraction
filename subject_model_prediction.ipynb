{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ff47d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Subject Code: 19AI44\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define the CRNN class (must match the training code exactly)\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 64, 16, W/2)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 128, 8, W/4)\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 256, 4, W/4)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # (N, 512, 2, W/4)\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(512, 512, kernel_size=(2,1)),  # (N, 512, 1, W/4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rnn = nn.LSTM(512, 256, num_layers=2, bidirectional=True, dropout=0.3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes)  # 512 because bidirectional (256 * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)  # (N, 512, 1, W/4)\n",
    "        x = x.squeeze(2)  # (N, 512, W/4)\n",
    "        x = x.permute(2, 0, 1)  # (W/4, N, 512) for LSTM\n",
    "        x, _ = self.rnn(x)  # (W/4, N, 512)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # (W/4, N, num_classes)\n",
    "        return x\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model with num_classes=37 (blank + 0-9 + A-Z)\n",
    "model = CRNN(num_classes=37)\n",
    "model.to(device)\n",
    "\n",
    "# Load the saved model (assuming it contains only the state_dict)\n",
    "best_model_path = 'best_subject_model_final.pth'\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)  # Load directly as state_dict\n",
    "model.eval()\n",
    "\n",
    "# Define the transform (matches val_test_transform from training)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),  # Matches subject code training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define the character mapping (matches training code)\n",
    "char_map = {i: str(i-1) for i in range(1, 11)}  # 1-10 -> '0'-'9'\n",
    "char_map.update({i: chr(i - 11 + ord('A')) for i in range(11, 37)})  # 11-36 -> 'A'-'Z'\n",
    "\n",
    "# Prediction function for subject code\n",
    "def predict_subject_code(model, image_path, device, transform, char_map):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # (1, 1, 32, 128)\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image)  # (W/4, 1, 37)\n",
    "        output = output.squeeze(1)  # (W/4, 37)\n",
    "        output = output.softmax(1).argmax(1)  # (W/4,)\n",
    "        seq = output.cpu().numpy()\n",
    "        prev = 0  # Initialize with blank character index\n",
    "        result = []\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:  # Skip blanks and repeats\n",
    "                result.append(char_map.get(s, ''))\n",
    "            prev = s\n",
    "    return ''.join(result)\n",
    "\n",
    "# Test with an image\n",
    "image_path = '19AI44.jpg'  # Replace with your image path\n",
    "predicted_code = predict_subject_code(model, image_path, device, val_test_transform, char_map)\n",
    "print(f\"Predicted Subject Code: {predicted_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########  IMPROVISED MODEL #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef123f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e6bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full model instance.\n",
      "Predicted Subject Code: 19AI414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from typing import Mapping\n",
    "\n",
    "# Define the CRNN class (must match the training code exactly)\n",
    "# This is the updated class provided by the user\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_h, nc, nclass, nh, n_rnn=2, leaky_relu=False, rnn_type='LSTM'):\n",
    "        \"\"\"\n",
    "        img_h: Input image height (e.g., 32)\n",
    "        nc: Number of input channels (1 for grayscale)\n",
    "        nclass: Number of output classes (e.g., 37: 26 letters + 10 digits + 1 blank)\n",
    "        nh: Size of the RNN hidden state\n",
    "        n_rnn: Number of RNN layers\n",
    "        leaky_relu: Whether to use LeakyReLU instead of ReLU\n",
    "        rnn_type: 'LSTM' or 'GRU'\n",
    "        \"\"\"\n",
    "        super(CRNN, self).__init__()\n",
    "        assert img_h % 16 == 0, 'img_h has to be a multiple of 16'\n",
    "        self.num_classes = nclass\n",
    "\n",
    "        # CNN Backbone\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "        def conv_relu_bn(i, leaky=False):\n",
    "            n_in = nc if i == 0 else nm[i - 1]\n",
    "            n_out = nm[i]\n",
    "            cnn.add_module(f'conv{i}', nn.Conv2d(n_in, n_out, ks[i], ss[i], ps[i]))\n",
    "            cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(n_out))\n",
    "            activation = nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(True)\n",
    "            cnn.add_module(f'relu{i}', activation)\n",
    "\n",
    "        # CNN layers with pooling\n",
    "        conv_relu_bn(0, leaky=leaky_relu); cnn.add_module('pooling0', nn.MaxPool2d(2, 2)) # H=16\n",
    "        conv_relu_bn(1, leaky=leaky_relu); cnn.add_module('pooling1', nn.MaxPool2d(2, 2)) # H=8\n",
    "        conv_relu_bn(2, leaky=leaky_relu); conv_relu_bn(3, leaky=leaky_relu)\n",
    "        cnn.add_module('pooling2', nn.MaxPool2d((2, 2), (2, 1), (0, 1))) # H=4\n",
    "        conv_relu_bn(4, leaky=leaky_relu); conv_relu_bn(5, leaky=leaky_relu)\n",
    "        cnn.add_module('pooling3', nn.MaxPool2d((2, 2), (2, 1), (0, 1))) # H=2\n",
    "        conv_relu_bn(6, leaky=leaky_relu) # H=1\n",
    "\n",
    "        self.cnn = cnn\n",
    "        rnn_input_size = nm[-1] # 512\n",
    "\n",
    "        # RNN Layers\n",
    "        rnn_dropout = 0.3 if n_rnn > 1 else 0\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(rnn_input_size, nh, num_layers=n_rnn,\n",
    "                               bidirectional=True, dropout=rnn_dropout,\n",
    "                               batch_first=False)\n",
    "        elif rnn_type == 'GRU':\n",
    "             self.rnn = nn.GRU(rnn_input_size, nh, num_layers=n_rnn,\n",
    "                               bidirectional=True, dropout=rnn_dropout,\n",
    "                               batch_first=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported RNN type: {rnn_type}\")\n",
    "\n",
    "        rnn_output_size = nh * 2 # Because bidirectional\n",
    "\n",
    "        # Classifier\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(rnn_output_size, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        conv = self.cnn(x) # (N, C, H, W) -> (N, 512, 1, W/4)\n",
    "        n, c, h, w = conv.size(); assert h == 1\n",
    "        conv = conv.squeeze(2).permute(2, 0, 1) # (W/4, N, 512)\n",
    "        # RNN processing\n",
    "        rnn_output, _ = self.rnn(conv) # (SeqLen, N, nh*2)\n",
    "        # Apply dropout\n",
    "        rnn_output = self.dropout(rnn_output)\n",
    "        # Final classification layer\n",
    "        output = self.fc(rnn_output) # (SeqLen, N, nclass)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the saved model (assuming it contains the entire model instance)\n",
    "best_model_path = 'best_full_subject_code_crnn_model.pth'\n",
    "\n",
    "# Check if the loaded object is a state_dict or the full model\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "if isinstance(checkpoint, Mapping):\n",
    "    # If it's a state_dict, initialize the model first and then load the state_dict\n",
    "    # Initialize the model with parameters matching training (assuming img_h=32, nc=1, nclass=37, nh=256, n_rnn=2, leaky_relu=False, rnn_type='LSTM')\n",
    "    # You need to adjust these parameters if your training used different values\n",
    "    model = CRNN(img_h=32, nc=1, nclass=37, nh=256, n_rnn=2, leaky_relu=False, rnn_type='LSTM')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Loaded model state_dict.\")\n",
    "elif isinstance(checkpoint, nn.Module):\n",
    "    # If it's the full model instance, load it directly\n",
    "    model = checkpoint\n",
    "    print(\"Loaded full model instance.\")\n",
    "else:\n",
    "    raise TypeError(f\"Expected model checkpoint to be a state_dict or a Module, but got {type(checkpoint)}\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the transform (matches val_test_transform from training, assuming size is 32x128)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define the character mapping (matches training code, assuming 0 is blank)\n",
    "# 0: blank\n",
    "# 1-10: '0'-'9'\n",
    "# 11-36: 'A'-'Z'\n",
    "char_map = {i: str(i-1) for i in range(1, 11)}  # 1-10 -> '0'-'9'\n",
    "char_map.update({i: chr(i - 11 + ord('A')) for i in range(11, 37)})  # 11-36 -> 'A'-'Z'\n",
    "# Adding the blank character mapping explicitly for completeness, though typically skipped\n",
    "char_map[0] = '' # Represents the blank character\n",
    "\n",
    "# Prediction function for subject code\n",
    "def predict_subject_code(model, image_path, device, transform, char_map):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension (1, 1, H, W)\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image)  # (SeqLen, 1, num_classes)\n",
    "        output = output.squeeze(1)  # (SeqLen, num_classes)\n",
    "        # Get the index with the highest probability for each timestep\n",
    "        output = output.softmax(1).argmax(1)  # (SeqLen,)\n",
    "        seq = output.cpu().numpy()\n",
    "\n",
    "        # Decode the sequence using CTC-like decoding (remove duplicates and blanks)\n",
    "        result = []\n",
    "        prev = 0  # Initialize with blank character index (assuming 0 is blank)\n",
    "        for s in seq:\n",
    "            if s != 0 and s != prev:  # Skip blanks (0) and consecutive duplicates\n",
    "                 # Ensure s is in char_map before trying to access it\n",
    "                 if s in char_map:\n",
    "                    result.append(char_map[s])\n",
    "            prev = s # Update previous character\n",
    "\n",
    "    return ''.join(result)\n",
    "\n",
    "# Test with an image\n",
    "image_path = '19AI44.jpg'  # Replace with your image path\n",
    "try:\n",
    "    predicted_code = predict_subject_code(model, image_path, device, val_test_transform, char_map)\n",
    "    print(f\"Predicted Subject Code: {predicted_code}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Image file not found at {image_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
